{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Jigsaw2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EokSNxD3O7m",
        "colab_type": "text"
      },
      "source": [
        "# Problem Statement.\n",
        "## Given a comment classify it into toxic or non-toxic. Here toxic means comments that are unacceptable to a person or a community.\n",
        "\n",
        "## This project was inspired from the jigsaw unintended bias toxic comment classification which was hosted on kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0p9huIa3086",
        "colab_type": "text"
      },
      "source": [
        "# The problem that we are solving here.\n",
        "## Background : \n",
        "### This problem was also solved earlier but there was a problem with the system . The system was a bit biased towards the use of unparliamentary/abusive words.\n",
        "### For example a sentence \"I am a gay\" or \"I am a black man.\" were classified as toxic comments. \n",
        "### Therefore the challenge was to get rid of this bias. To solve this problem a new metric was introduced by jigsaw. This metric also considers the identity of the person about whom the comment is made. You can get into  the details of the metric on the below link.\n",
        "<a href=\"https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\">Click Here</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WHF2FAsYj8L",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory  Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en1qQYZT29rn",
        "colab_type": "code",
        "outputId": "e664bdd7-c116-456f-caa9-68f259f478c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMXpvJcYj8N",
        "colab_type": "code",
        "outputId": "f5735f3f-2bf6-49ea-d785-72aca3b95d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Project/train.csv\")\n",
        "df.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>severe_toxicity</th>\n",
              "      <th>obscene</th>\n",
              "      <th>identity_attack</th>\n",
              "      <th>insult</th>\n",
              "      <th>threat</th>\n",
              "      <th>asian</th>\n",
              "      <th>atheist</th>\n",
              "      <th>bisexual</th>\n",
              "      <th>black</th>\n",
              "      <th>buddhist</th>\n",
              "      <th>christian</th>\n",
              "      <th>female</th>\n",
              "      <th>heterosexual</th>\n",
              "      <th>hindu</th>\n",
              "      <th>homosexual_gay_or_lesbian</th>\n",
              "      <th>intellectual_or_learning_disability</th>\n",
              "      <th>jewish</th>\n",
              "      <th>latino</th>\n",
              "      <th>male</th>\n",
              "      <th>muslim</th>\n",
              "      <th>other_disability</th>\n",
              "      <th>other_gender</th>\n",
              "      <th>other_race_or_ethnicity</th>\n",
              "      <th>other_religion</th>\n",
              "      <th>other_sexual_orientation</th>\n",
              "      <th>physical_disability</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>transgender</th>\n",
              "      <th>white</th>\n",
              "      <th>created_date</th>\n",
              "      <th>publication_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>sad</th>\n",
              "      <th>likes</th>\n",
              "      <th>disagree</th>\n",
              "      <th>sexual_explicit</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-09-29 10:50:41.987077+00</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Thank you!! This would make my life a lot less...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-09-29 10:50:42.870083+00</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>This is such an urgent design problem; kudos t...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-09-29 10:50:45.222647+00</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Is this something I'll be able to install on m...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-09-29 10:50:47.601894+00</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59856</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>haha you guys are a bunch of losers.</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.87234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015-09-29 10:50:48.488476+00</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id    target  ... identity_annotator_count  toxicity_annotator_count\n",
              "0  59848  0.000000  ...                        0                         4\n",
              "1  59849  0.000000  ...                        0                         4\n",
              "2  59852  0.000000  ...                        0                         4\n",
              "3  59855  0.000000  ...                        0                         4\n",
              "4  59856  0.893617  ...                        4                        47\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqDZlqmdYj8V",
        "colab_type": "code",
        "outputId": "c08a7663-40d8-4ced-df5e-c320facfc232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#print(df.shape)\n",
        "#df = df.sample(500000)\n",
        "print(df.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1804874, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UwqAY0BwEDN",
        "colab_type": "code",
        "outputId": "632a7e2a-8aa6-4ce2-aaa3-484c55b3e8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = df.drop_duplicates(subset={'comment_text'},keep='first')\n",
        "df.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1780823, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFY0EQn2Yj9K",
        "colab_type": "text"
      },
      "source": [
        "### Looking the absuive words used in the comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwfe7u52Yj9M",
        "colab_type": "code",
        "outputId": "49be1be6-b8cf-4c73-e4da-a848ea1d89a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Lets find the words that contains letters or character that are not present in english\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "non_eng_words = {}\n",
        "pattern = re.compile(r'([fadpbit]{1,4}[*]{1,4}[ingkscyhabd]{1,4})')\n",
        "\n",
        "for sent in tqdm(df['comment_text'].values):\n",
        "    sent = re.sub(r'[^a-zA-Z* ]',' ',sent)\n",
        "    for wrd in sent.split():\n",
        "        if(re.match(pattern,wrd) and len(wrd)>2):\n",
        "            if(non_eng_words.get(wrd,-1)<0):\n",
        "                non_eng_words[wrd] = 1\n",
        "            else:\n",
        "                non_eng_words[wrd] += 1"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1780823/1780823 [02:01<00:00, 14638.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm68pnCKYj9a",
        "colab_type": "code",
        "outputId": "5e6d244e-4a10-4c3f-82c3-42594006d82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Now we will store these words and their counts in a list.\n",
        "wrds = []\n",
        "counts = []\n",
        "for wrd in sorted(non_eng_words, key=non_eng_words.get, reverse=True):\n",
        "    if(len(wrd)<30):\n",
        "        wrds.append(wrd)\n",
        "        counts.append(non_eng_words[wrd])\n",
        "print(\"Number of aabusive words wused are \".format(len(non_eng_words)))\n",
        "        \n",
        "## Abusive words present in the comments.\n",
        "for i in range(len(wrds)):\n",
        "    print(wrds[i],\"->\",counts[i])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of aabusive words wused are \n",
            "p***y -> 73\n",
            "p*ssy -> 65\n",
            "f**k -> 45\n",
            "a**hole -> 38\n",
            "f*ck -> 29\n",
            "a**holes -> 27\n",
            "p*ss -> 25\n",
            "f*cking -> 18\n",
            "f***ing -> 17\n",
            "f**king -> 15\n",
            "p*ssed -> 13\n",
            "p**sy -> 13\n",
            "a*s -> 10\n",
            "f**ked -> 10\n",
            "b***h -> 9\n",
            "f*cked -> 8\n",
            "d*ck -> 7\n",
            "p**s -> 7\n",
            "p*ssie -> 6\n",
            "p*ssing -> 6\n",
            "a**clown -> 6\n",
            "bit*h -> 5\n",
            "d**k -> 5\n",
            "b**ch -> 5\n",
            "f*cks -> 4\n",
            "p**y -> 4\n",
            "d****d -> 3\n",
            "p***ing -> 3\n",
            "pi*s -> 3\n",
            "p***ies -> 3\n",
            "p*nis -> 3\n",
            "b*itch -> 3\n",
            "d**n -> 3\n",
            "d**ks -> 3\n",
            "b*stards -> 3\n",
            "f**cker -> 3\n",
            "p****y -> 3\n",
            "a**clowns -> 3\n",
            "p****d -> 2\n",
            "pi**ing -> 2\n",
            "bi*ch -> 2\n",
            "a*sholes -> 2\n",
            "f**ks -> 2\n",
            "f*k -> 2\n",
            "a*se -> 2\n",
            "f***in -> 2\n",
            "f***n -> 2\n",
            "d*amn -> 2\n",
            "f**kin -> 2\n",
            "p*ss* -> 2\n",
            "p*ssies -> 2\n",
            "f****d -> 2\n",
            "f****ing -> 2\n",
            "a**hats -> 2\n",
            "b***s -> 2\n",
            "p*sses -> 2\n",
            "p*ss*ng -> 2\n",
            "f***king -> 2\n",
            "b*stard -> 2\n",
            "p*s*y -> 2\n",
            "f*ckers -> 2\n",
            "d*ckhead -> 2\n",
            "f****s -> 2\n",
            "a***holes -> 2\n",
            "a*holes -> 2\n",
            "t**d -> 2\n",
            "f*ckin -> 1\n",
            "b**ching -> 1\n",
            "a*a* -> 1\n",
            "f*c*ing -> 1\n",
            "bat*hit -> 1\n",
            "f***g -> 1\n",
            "d***s -> 1\n",
            "a*shole -> 1\n",
            "p****s -> 1\n",
            "b*sta*ds -> 1\n",
            "p**s* -> 1\n",
            "p****ies -> 1\n",
            "b*gg*r -> 1\n",
            "f*c*king -> 1\n",
            "f***s -> 1\n",
            "a*ss -> 1\n",
            "bat****crazy -> 1\n",
            "p*sspot -> 1\n",
            "p***ys -> 1\n",
            "ba**ards -> 1\n",
            "f**kc -> 1\n",
            "di*k -> 1\n",
            "f*ck*d -> 1\n",
            "b*alls -> 1\n",
            "di*ks -> 1\n",
            "f*c* -> 1\n",
            "b****h -> 1\n",
            "f*kcyouCanada -> 1\n",
            "t*g -> 1\n",
            "a**h*** -> 1\n",
            "f**ken -> 1\n",
            "f**g -> 1\n",
            "f**ing -> 1\n",
            "a**holery -> 1\n",
            "f**kem -> 1\n",
            "i*iot -> 1\n",
            "a**hat -> 1\n",
            "f**cking -> 1\n",
            "f**ching -> 1\n",
            "d*icks -> 1\n",
            "t*i*t -> 1\n",
            "a**h**e -> 1\n",
            "f***ked -> 1\n",
            "b***s**t -> 1\n",
            "b*st*rd -> 1\n",
            "b***ch -> 1\n",
            "p*as -> 1\n",
            "a****and -> 1\n",
            "f*ggots -> 1\n",
            "da*n -> 1\n",
            "a**h* -> 1\n",
            "f**cked -> 1\n",
            "t*h -> 1\n",
            "id*iot -> 1\n",
            "b****s -> 1\n",
            "bit*hes -> 1\n",
            "b***ches -> 1\n",
            "fa**in -> 1\n",
            "b**hes -> 1\n",
            "da*ned -> 1\n",
            "p**a -> 1\n",
            "t**s -> 1\n",
            "di*cks -> 1\n",
            "d**ned -> 1\n",
            "f*ckup -> 1\n",
            "a***hole -> 1\n",
            "p*sssy -> 1\n",
            "a*hole -> 1\n",
            "f***k -> 1\n",
            "p****grabber -> 1\n",
            "f***able -> 1\n",
            "bi**h -> 1\n",
            "a**ing -> 1\n",
            "d*do -> 1\n",
            "p**ck -> 1\n",
            "di**s -> 1\n",
            "f*ggot -> 1\n",
            "d*ke -> 1\n",
            "f*g -> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWuYp_sL-kKB",
        "colab_type": "text"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqwmrvE-Yj9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Ref: https://www.kaggle.com/haqishen/jigsaw-predict\n",
        "# We are creating a dict with shortened word as key and actual word as value.\n",
        "apostophe_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                  \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                  \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\",\n",
        "                  \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\",\n",
        "                  \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\",\n",
        "                  \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\",\n",
        "                  \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n",
        "                  \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
        "                  \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                  \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                  \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                  \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
        "                  \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
        "                  \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                  \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
        "                  \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
        "                  \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n",
        "                  \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "                  \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                  \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\",\n",
        "                  \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
        "                  \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\",\n",
        "                  \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                  \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
        "                  \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
        "                  \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                  \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\",\n",
        "                  \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
        "                  \"you've\": \"you have\" }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEeOYrHj9B7i",
        "colab_type": "code",
        "outputId": "43c4d13e-a8fa-4889-9b70-2fd623a47189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = list(stopwords.words('english'))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7rKRNfa9CLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def process_sent(sent):\n",
        "    line = ''\n",
        "    for wrd in sent.split():\n",
        "        if(len(apostophe_dict.get(wrd.lower(),'n'))>1 and wrd.lower() not in stopwords and len(wrd)>2):\n",
        "            wrd = apostophe_dict[wrd.lower()]\n",
        "            n_wrd = ''\n",
        "            for w in wrd.split():\n",
        "                if(w not in stopwords):\n",
        "                    n_wrd += \" \"+w\n",
        "            line += \" \"+n_wrd\n",
        "        else:\n",
        "            line += \" \"+ wrd.lower()    \n",
        "    line = re.sub(r'[^a-zA-Z* ]',' ',line)\n",
        "    return line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAkmxr6Y-2or",
        "colab_type": "code",
        "outputId": "15f0baa4-1042-4068-a6b8-1f0ab9767a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocessing the comments.\n",
        "preprocessed_data = []\n",
        "from tqdm import tqdm\n",
        "for sent in tqdm(df['comment_text'].values):\n",
        "    sent = process_sent(sent)\n",
        "    line = ''\n",
        "    for wrd in sent.split():\n",
        "        if(len(wrd)>2):\n",
        "            line += \" \" +wrd.lower()\n",
        "    line = re.sub(r\"[']\",'',line)\n",
        "    preprocessed_data.append(line)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1780823/1780823 [01:28<00:00, 20101.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBoBrIuz-2iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['comment_text'] = preprocessed_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHh3Vpfo_jji",
        "colab_type": "text"
      },
      "source": [
        "### Splitting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbd5sTCL7l0s",
        "colab_type": "code",
        "outputId": "ebff327e-f76b-4090-f45e-13584773a036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Y = df['target'].values\n",
        "train,test,Y_train,Y_test = train_test_split(df,Y,test_size=0.2,random_state=42)\n",
        "train,cv,Y_train,Y_cv = train_test_split(train,Y_train,test_size=0.1,random_state=42)\n",
        "print((train.shape),(test.shape),(cv.shape))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1282192, 45) (356165, 45) (142466, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBeovSv8GiZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "identity_columns = [\n",
        "        'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
        "        'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9s2VwFHNqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "seed = 1029\n",
        "\n",
        "train_x = train['comment_text'].fillna('_##_').values\n",
        "test_x = test['comment_text'].fillna('_##_').values\n",
        "cv_x = cv['comment_text'].fillna('_##_').values\n",
        "\n",
        "# For gtrain\n",
        "weights = np.ones((len(train),))\n",
        "weights += train[identity_columns].fillna(0).values.sum(axis=1) * 3\n",
        "weights += train['target'].values * 8\n",
        "weights /= weights.max()\n",
        "train_y = np.vstack([train['target'], weights]).T   \n",
        "train_y_identity = train[identity_columns].values\n",
        "\n",
        "# For test\n",
        "weights = np.ones((len(test),))\n",
        "weights += test[identity_columns].fillna(0).values.sum(axis=1) * 3\n",
        "weights += test['target'].values * 8\n",
        "weights /= weights.max()\n",
        "test_y = np.vstack([test['target'], weights]).T   \n",
        "test_y_identity = test[identity_columns].values\n",
        "\n",
        "# For cv\n",
        "weights = np.ones((len(cv),))\n",
        "weights += cv[identity_columns].fillna(0).values.sum(axis=1) * 3\n",
        "weights += cv['target'].values * 8\n",
        "weights /= weights.max()\n",
        "cv_y = np.vstack([cv['target'], weights]).T    \n",
        "cv_y_identity = cv[identity_columns].values\n",
        "\n",
        "# shuffling the data\n",
        "np.random.seed(seed)\n",
        "train_idx = np.random.permutation(len(train_x))\n",
        "test_idx = np.random.permutation(len(test_x))\n",
        "cv_idx = np.random.permutation(len(cv_x))\n",
        "\n",
        "train_x = train_x[train_idx]\n",
        "train_y = train_y[train_idx]\n",
        "train_y_identity = train_y_identity[train_idx]\n",
        "\n",
        "\n",
        "test_x = test_x[test_idx]\n",
        "test_y = test_y[test_idx]\n",
        "test_y_identity = test_y_identity[test_idx]\n",
        "\n",
        "\n",
        "cv_x = cv_x[cv_idx]\n",
        "cv_y = cv_y[cv_idx]\n",
        "cv_y_identity = cv_y_identity[cv_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVMR8tQVSRNE",
        "colab_type": "code",
        "outputId": "f084ab78-0740-4a30-d933-2d30a3d37f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_binary = (test_y[:, 0] >= 0.5).astype(int)\n",
        "y_identity_binary = (test_y_identity >= 0.5).astype(int)\n",
        "y_identity_binary.shape\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(356165, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R-S5srPCmTS",
        "colab_type": "code",
        "outputId": "1d69b00d-73f4-4df0-a478-a5bf87856992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train = (train_y[:,0]>=0.5).astype(int)\n",
        "Y_cv = (cv_y[:,0]>=0.5).astype(int)\n",
        "Y_test = (test_y[:,0]>=0.5).astype(int)\n",
        "print(Y_train.shape, Y_cv.shape)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1282192,) (142466,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZlZwaRiI4Zf",
        "colab_type": "text"
      },
      "source": [
        "### Custom metric given by *Kaggle*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmbsUXNavCwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This metric code below was taken from kaggle \n",
        "from sklearn.metrics import roc_auc_score\n",
        "import keras.backend as K\n",
        "class JigsawEvaluator:\n",
        "    \n",
        "    def __init__(self, y_binary, y_identity_binary, power=-5, overall_model_weight=0.25):\n",
        "        self.y = y_binary\n",
        "        self.y_i = y_identity_binary\n",
        "        self.n_subgroups = self.y_i.shape[1]\n",
        "        self.power = power\n",
        "        self.overall_model_weight = overall_model_weight\n",
        "        \n",
        "    @staticmethod\n",
        "    def _compute_auc(y_true, y_pred):\n",
        "        try:\n",
        "            return roc_auc_score(y_true, y_pred)\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "        \n",
        "    def _compute_subgroup_auc(self, i, y_pred):\n",
        "        mask = self.y_i[:, i] == 1\n",
        "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
        "        \n",
        "    def _compute_bpsn_auc(self, i, y_pred):\n",
        "        mask = self.y_i[:, i] + self.y == 1\n",
        "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
        "        \n",
        "    def _compute_bnsp_auc(self, i, y_pred):\n",
        "        mask = self.y_i[:, i] + self.y != 1\n",
        "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
        "      \n",
        "    def compute_bias_metrics_for_model(self, y_pred):\n",
        "        records = np.zeros((3, self.n_subgroups))\n",
        "        for i in range(self.n_subgroups):\n",
        "            records[0, i] = self._compute_subgroup_auc(i, y_pred)\n",
        "            records[1, i] = self._compute_bpsn_auc(i, y_pred)\n",
        "            records[2, i] = self._compute_bnsp_auc(i, y_pred)\n",
        "        return records\n",
        "        \n",
        "    def _calculate_overall_auc(self, y_pred):\n",
        "        return roc_auc_score(self.y, y_pred)\n",
        "        \n",
        "    def _power_mean(self, array):\n",
        "        total = sum(np.power(array, self.power))\n",
        "        return np.power(total / len(array), 1 / self.power)\n",
        "        \n",
        "    def get_final_metric(self, y_pred):\n",
        "        #y_pred = K.flatten(y_pred)\n",
        "        bias_metrics = self.compute_bias_metrics_for_model(y_pred)\n",
        "        bias_score = np.average([\n",
        "            self._power_mean(bias_metrics[0]),\n",
        "            self._power_mean(bias_metrics[1]),\n",
        "            self._power_mean(bias_metrics[2])\n",
        "        ])\n",
        "        overall_score = self.overall_model_weight * self._calculate_overall_auc(y_pred)\n",
        "        bias_score = (1 - self.overall_model_weight) * bias_score\n",
        "        return overall_score + bias_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMIWJJa1PYRA",
        "colab_type": "text"
      },
      "source": [
        "## Vectorizing datset using tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeNjR0XTVYK6",
        "colab_type": "text"
      },
      "source": [
        "#### vectorizing train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCavHB4HUe3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target with value greater than equal to 0.5 will be assigned 1 and rest 0.\n",
        "def fun(x):\n",
        "    if(x>=0.5):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rh7cbCMUfBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df['target']\n",
        "Y = labels.map(fun)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5AS38gZYj_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b02c199-389f-4055-ef13-cbce815a36e9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(preprocessed_data,Y,test_size=0.2,random_state=42)\n",
        "X_train,X_cv,Y_train,Y_cv = train_test_split(X_train,Y_train,test_size=0.1,random_state=42)\n",
        "print(len(X_train),len(X_test),len(X_cv))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1282192 356165 142466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vEFdbPoU3wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(min_df=5, max_features=50000)\n",
        "train_vect1 = vectorizer.fit_transform(X_train)\n",
        "test_vect1 = vectorizer.transform(X_test)\n",
        "cv_vect1 = vectorizer.transform(X_cv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_BfZFUdYj_F",
        "colab_type": "code",
        "outputId": "ea39c091-8753-42f3-bb3b-1592b9632e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_vect1.shape)\n",
        "print(test_vect1.shape)\n",
        "print(cv_vect1.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1282192, 50000)\n",
            "(356165, 50000)\n",
            "(142466, 50000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJlRT7XxVcdf",
        "colab_type": "text"
      },
      "source": [
        "#### vectorizing test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qXCQhK0VdHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "925c9be5-4f01-4b52-b0e6-6900f375af19"
      },
      "source": [
        "test_df = pd.read_csv(\"/content/drive/My Drive/Project/test.csv\")\n",
        "test_df.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7097320</td>\n",
              "      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7097321</td>\n",
              "      <td>This is malfeasance by the Administrator and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7097322</td>\n",
              "      <td>@Rmiller101 - Spoken like a true elitist. But ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7097323</td>\n",
              "      <td>Paul: Thank you for your kind words.  I do, in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7097324</td>\n",
              "      <td>Sorry you missed high school. Eisenhower sent ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                       comment_text\n",
              "0  7097320  [ Integrity means that you pay your debts.]\\n\\...\n",
              "1  7097321  This is malfeasance by the Administrator and t...\n",
              "2  7097322  @Rmiller101 - Spoken like a true elitist. But ...\n",
              "3  7097323  Paul: Thank you for your kind words.  I do, in...\n",
              "4  7097324  Sorry you missed high school. Eisenhower sent ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaFdiBUIVdEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32796e01-e6e0-4b2a-8655-0b26ec0d91bc"
      },
      "source": [
        "# Preprocessing the comments.\n",
        "preprocessed_data_test = []\n",
        "from tqdm import tqdm\n",
        "for sent in tqdm(test_df['comment_text'].values):\n",
        "    sent = process_sent(sent)\n",
        "    line = ''\n",
        "    for wrd in sent.split():\n",
        "        if(len(wrd)>2):\n",
        "            line += \" \" +wrd.lower()\n",
        "    #line = re.sub(r\"[']\",'',line)\n",
        "    preprocessed_data_test.append(line)\n",
        "    \n",
        "# Preparing the test data\n",
        "test_X = vectorizer.transform(preprocessed_data)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 97320/97320 [00:05<00:00, 16753.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCbzpZf8Yj_W",
        "colab_type": "text"
      },
      "source": [
        "# Training Logistic Regression on tfidf vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ljlSUAScUg",
        "colab_type": "text"
      },
      "source": [
        "### On word unigrams "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIS0fQ5uYj_X",
        "colab_type": "code",
        "outputId": "e0d9669e-8abb-42f7-a00d-0bd8417481d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "params = [0.0000001,0.000001,0.00001,0.0001,0.001,0.01,0.1,1.0,10,100]\n",
        "train_auc = []\n",
        "cv_auc = []\n",
        "for i in tqdm(params):\n",
        "    lr = SGDClassifier(loss='log',penalty='l2',tol=0.0001,alpha=i,n_jobs=-1,class_weight='balanced')\n",
        "    model = CalibratedClassifierCV(lr,cv=5)\n",
        "    model.fit(train_vect1,Y_train)\n",
        "    predict_y_train = model.predict_proba(train_vect1)[:,1] # Taking probability for positive class\n",
        "    t_auc = roc_auc_score(Y_train,predict_y_train)\n",
        "    predict_y_cv = model.predict_proba(cv_vect1)[:,1]# Taking probability for positve class\n",
        "    c_auc = roc_auc_score(Y_cv,predict_y_cv)\n",
        "    train_auc.append(t_auc)\n",
        "    cv_auc.append(c_auc)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [06:34<59:07, 394.17s/it]\u001b[A\n",
            " 20%|██        | 2/10 [09:16<43:17, 324.68s/it]\u001b[A\n",
            " 30%|███       | 3/10 [10:48<29:44, 254.91s/it]\u001b[A\n",
            " 40%|████      | 4/10 [11:52<19:46, 197.69s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [12:39<12:41, 152.30s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [13:24<08:00, 120.14s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [13:57<04:42, 94.05s/it] \u001b[A\n",
            " 80%|████████  | 8/10 [14:30<02:31, 75.80s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [15:05<01:03, 63.53s/it]\u001b[A\n",
            "100%|██████████| 10/10 [15:36<00:00, 53.68s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmjtJl98Yj_b",
        "colab_type": "code",
        "outputId": "63d312fa-bb76-4541-e78b-ab4c81563bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math as m\n",
        "para = [m.log10(x) for x in params]\n",
        "plt.plot(para,train_auc,label='train auc')\n",
        "plt.plot(para,cv_auc,label='validation auc')\n",
        "plt.xlabel(\"log of hyper parameter lambda\")\n",
        "plt.ylabel(\"Auc for each lambda\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhP3kFHlYj_i",
        "colab_type": "code",
        "outputId": "95ce4051-90ac-4824-fd53-546b99c83abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "lr = SGDClassifier(loss='log',penalty='l2',tol=0.0001,alpha=0.000001,n_jobs=-1)\n",
        "model = CalibratedClassifierCV(lr,cv=5)\n",
        "model.fit(train_vect1,Y_train)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=1e-06, average=False,\n",
              "                                                    class_weight=None,\n",
              "                                                    early_stopping=False,\n",
              "                                                    epsilon=0.1, eta0=0.0,\n",
              "                                                    fit_intercept=True,\n",
              "                                                    l1_ratio=0.15,\n",
              "                                                    learning_rate='optimal',\n",
              "                                                    loss='log', max_iter=1000,\n",
              "                                                    n_iter_no_change=5,\n",
              "                                                    n_jobs=-1, penalty='l2',\n",
              "                                                    power_t=0.5,\n",
              "                                                    random_state=None,\n",
              "                                                    shuffle=True, tol=0.0001,\n",
              "                                                    validation_fraction=0.1,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                       cv=5, method='sigmoid')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwsLz3ypkHcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0455d4b-7b24-40c1-8897-74dd31a92470"
      },
      "source": [
        "predict_y_test = model.predict_proba(test_vect1)[:,1] # Taking probability for positive class\n",
        "eval = JigsawEvaluator(y_binary, y_identity_binary)\n",
        "auc = eval.get_final_metric(predict_y_test)\n",
        "print(\"Auc for logistic regression is {}\".format(roc_auc_score(Y_test,predict_y_test)))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc for logistic regression is 0.9465540641624216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKYF4x5uYj_n",
        "colab_type": "text"
      },
      "source": [
        "### Training Naive bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32kER6MhYj_o",
        "colab_type": "code",
        "outputId": "d53bfad1-3867-4577-b794-aea4615b172e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "param = [0.00001,0.0001,0.001,0.01,0.1,1.0,10,100]\n",
        "train_auc = []\n",
        "cv_auc = []\n",
        "\n",
        "for i in tqdm(param):\n",
        "    model = MultinomialNB(alpha=i)\n",
        "    model.fit(train_vect1, Y_train)\n",
        "    predict_y_train = model.predict_log_proba(train_vect1)[:,1] # Taking probability for positive class\n",
        "    t_auc = roc_auc_score(Y_train,predict_y_train)\n",
        "    predict_y_cv = model.predict_log_proba(cv_vect1)[:,1]# Taking probability for positve class\n",
        "    c_auc = roc_auc_score(Y_cv,predict_y_cv)\n",
        "    train_auc.append(t_auc)\n",
        "    cv_auc.append(c_auc)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:01<00:11,  1.61s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:03<00:09,  1.61s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:04<00:08,  1.61s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:06<00:06,  1.61s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:08<00:04,  1.61s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:09<00:03,  1.61s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:11<00:01,  1.60s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:12<00:00,  1.60s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG73kybSYj_u",
        "colab_type": "code",
        "outputId": "86f56712-0eb9-46fd-f2fe-8705bcf0ebcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math as m\n",
        "para = [m.log10(x) for x in param]\n",
        "plt.plot(para,train_auc,label='train auc')\n",
        "plt.plot(para,cv_auc,label='validation auc')\n",
        "plt.xlabel(\"log of hyper parameter lambda\")\n",
        "plt.ylabel(\"Auc for each lambda\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWBhjjAno/wP/fXQXyKlcMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMaVQWZaYj_0",
        "colab_type": "code",
        "outputId": "caf9fd52-68cb-4c25-9c52-582176858f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = MultinomialNB(alpha=1)\n",
        "model.fit(train_vect1, Y_train)\n",
        "predict_y_test = model.predict_log_proba(test_vect1)[:,1] # Taking probability for positive class\n",
        "print(\"Test auc for naive bayes model is {}\".format(roc_auc_score(Y_test,predict_y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test auc for naive bayes model is 0.8755791924694993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbotoes8YkB_",
        "colab_type": "text"
      },
      "source": [
        "## Using LSTM Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WhBWo9WcO-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downloaded = drive.CreateFile({'id':id}) \n",
        "#glove_file = downloaded.GetContentFile('glove.6B.100d.txt') \n",
        "\n",
        "f = open(\"/content/drive/My Drive/Project/glove.6B.300d.txt\",'r',encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIRU0rsTYkB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizing the essay text data for train dataset\n",
        "# We will train the vectorizer on train data and will use the same on test and cv data.\n",
        "# Credit : https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "# Tokenizing the essay text data for train dataset\n",
        "# We will train the vectorizer on train data and will use the same on test and cv data.\n",
        "# Credit : https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense,Input\n",
        "from numpy import asarray\n",
        "t  = Tokenizer(num_words=40000)\n",
        "t.fit_on_texts(train_x)\n",
        "vocab_size = len(t.word_index)+1\n",
        "# Integer coding all the words.\n",
        "encoded_essay = t.texts_to_sequences(train_x)\n",
        "# defining a max size for padding.\n",
        "max_len = 150\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "train_sequence = pad_sequences(encoded_essay,maxlen = max_len,padding='post')\n",
        "\n",
        "# Vectorizing test data\n",
        "# Integer coding all the words.\n",
        "encoded_essay = t.texts_to_sequences(test_x)\n",
        "# defining a max size for padding.\n",
        "max_len = 150\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "test_sequence = pad_sequences(encoded_essay,maxlen = max_len,padding='post')\n",
        "\n",
        "# Vectorizing cv data\n",
        "# Integer coding all the words.\n",
        "encoded_essay = t.texts_to_sequences(cv_x)\n",
        "# defining a max size for padding.\n",
        "max_len = 150\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "cv_sequence = pad_sequences(encoded_essay,maxlen = max_len,padding='post')\n",
        "\n",
        "# we will load the whole glove vectors .\n",
        "embeddings_index = {}\n",
        "# Opening the file\n",
        "f = open(\"/content/drive/My Drive/Project/glove.6B.300d.txt\",'r',encoding=\"utf-8\")\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFLf1fXSYkCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Credit : https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "import numpy as np\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fda3L5s7sZ1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0e042804-d6b4-4c61-c918-93cd53fb2b17"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "test_df = pd.read_csv(\"/content/drive/My Drive/Project/test.csv\")\n",
        "test_df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7097320</td>\n",
              "      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7097321</td>\n",
              "      <td>This is malfeasance by the Administrator and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7097322</td>\n",
              "      <td>@Rmiller101 - Spoken like a true elitist. But ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7097323</td>\n",
              "      <td>Paul: Thank you for your kind words.  I do, in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7097324</td>\n",
              "      <td>Sorry you missed high school. Eisenhower sent ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                       comment_text\n",
              "0  7097320  [ Integrity means that you pay your debts.]\\n\\...\n",
              "1  7097321  This is malfeasance by the Administrator and t...\n",
              "2  7097322  @Rmiller101 - Spoken like a true elitist. But ...\n",
              "3  7097323  Paul: Thank you for your kind words.  I do, in...\n",
              "4  7097324  Sorry you missed high school. Eisenhower sent ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnMbfg7gsZxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ee51cbc8-74cd-47f1-87a6-a266ba85806d"
      },
      "source": [
        "# Preprocessing the comments.\n",
        "test_preprocessed = []\n",
        "bad_found = []\n",
        "from tqdm import tqdm\n",
        "for sent in tqdm(test_df['comment_text'].values):\n",
        "    sent = process_sent(sent)\n",
        "    line = ''\n",
        "    for wrd in sent.split():\n",
        "        if(len(wrd)>2):\n",
        "            line += \" \" +wrd.lower()\n",
        "    line = re.sub(r\"[']\",'',line)\n",
        "    test_preprocessed.append(line)\n",
        "\n",
        "test_df['comment_text'] = test_preprocessed\n",
        "test_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 97320/97320 [00:06<00:00, 15795.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7097320</td>\n",
              "      <td>integrity means that you pay your debts does ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7097321</td>\n",
              "      <td>this malfeasance the administrator and the bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7097322</td>\n",
              "      <td>rmiller spoken like true elitist but look out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7097323</td>\n",
              "      <td>paul thank you for your kind words indeed hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7097324</td>\n",
              "      <td>sorry you missed high school eisenhower sent ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                       comment_text\n",
              "0  7097320   integrity means that you pay your debts does ...\n",
              "1  7097321   this malfeasance the administrator and the bo...\n",
              "2  7097322   rmiller spoken like true elitist but look out...\n",
              "3  7097323   paul thank you for your kind words indeed hav...\n",
              "4  7097324   sorry you missed high school eisenhower sent ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcpFgf1SddiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Vectorizing test data\n",
        "# Integer coding all the words.\n",
        "encoded_essay1 = t.texts_to_sequences(test_df['comment_text'])\n",
        "# defining a max size for padding.\n",
        "max_len = 150\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "test_sequence1 = pad_sequences(encoded_essay1,maxlen = max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI6ijwfIs9qW",
        "colab_type": "text"
      },
      "source": [
        "# First Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5jhe5y7ekrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1f05d16b-8165-4dc5-f72e-4d9e1fed0175"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Dropout, BatchNormalization, Input, SpatialDropout1D\n",
        "from keras.layers import Dense, Bidirectional, concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "import keras.backend as K\n",
        "\n",
        "embedding_vector_length = 100\n",
        "input1 = Input(shape=(150,))\n",
        "e1 = Embedding(40000,embedding_vector_length, input_length=150)(input1)\n",
        "x1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(e1)\n",
        "att = SeqSelfAttention(attention_activation='sigmoid')(x1)\n",
        "\n",
        "x1 = Flatten()(att)\n",
        "output = Dense(1, activation='sigmoid')(x1)\n",
        "model = Model(inputs=[input1,], outputs=[output])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',])\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 150, 100)          4000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 150, 256)          234496    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_5 (SeqSel (None, 150, 256)          16449     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 38400)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 38401     \n",
            "=================================================================\n",
            "Total params: 4,289,346\n",
            "Trainable params: 4,289,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdFfNlk1e7au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "06844879-852b-48eb-d05d-db35d0a50128"
      },
      "source": [
        "model.fit(train_sequence, Y_train, nb_epoch=5, batch_size=512, validation_data=(cv_sequence, Y_cv))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1282192 samples, validate on 142466 samples\n",
            "Epoch 1/5\n",
            "1282192/1282192 [==============================] - 2665s 2ms/step - loss: 0.1483 - acc: 0.9454 - val_loss: 0.1334 - val_acc: 0.9491\n",
            "Epoch 2/5\n",
            "1282192/1282192 [==============================] - 2657s 2ms/step - loss: 0.1256 - acc: 0.9515 - val_loss: 0.1307 - val_acc: 0.9495\n",
            "Epoch 3/5\n",
            "1282192/1282192 [==============================] - 2654s 2ms/step - loss: 0.1155 - acc: 0.9552 - val_loss: 0.1330 - val_acc: 0.9494\n",
            "Epoch 4/5\n",
            "1282192/1282192 [==============================] - 2659s 2ms/step - loss: 0.1037 - acc: 0.9600 - val_loss: 0.1407 - val_acc: 0.9477\n",
            "Epoch 5/5\n",
            "1282192/1282192 [==============================] - 2665s 2ms/step - loss: 0.0924 - acc: 0.9646 - val_loss: 0.1522 - val_acc: 0.9463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0bd2deaf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1W7ZufTe7Wt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f04495f-0790-4150-d9a8-88d3c53fa7aa"
      },
      "source": [
        "# Roc auc\n",
        "predicted_y = model.predict(test_sequence,batch_size=512)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(Y_test,predicted_y))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9358755310733398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smCQ902La-cO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1caba7ca-3263-4e86-cd3c-0a00b67e7974"
      },
      "source": [
        "eval = JigsawEvaluator(y_binary, y_identity_binary)\n",
        "print(eval.get_final_metric(predicted_y))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8823309859591929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al19mijyZq9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pre = model.predict(test_sequence1,batch_size=512)\n",
        "submission = pd.DataFrame({'id': test_df['id'].values})\n",
        "submission['prediction'] = y_pre\n",
        "submission.to_csv(\"submissionNew2.csv\",index=False) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mled4ZmNZrLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download( \"/content/submissionNew2.csv\" )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DWPQ8JNOGY",
        "colab_type": "text"
      },
      "source": [
        "## First Bi-LSTM architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyOSj3q2YkCL",
        "colab_type": "code",
        "outputId": "d348acb4-f330-4c5d-895d-f586a0639b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten, GlobalMaxPool1D\n",
        "from keras.layers import Dropout, BatchNormalization\n",
        "from keras.layers import Dense, Bidirectional\n",
        "from keras.models import Model\n",
        "\n",
        "embedding_vecor_length = 64\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vecor_length, input_shape=(150,)))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(GlobalMaxPllo1D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(768,activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "model.add(GlobalMaxPllo1D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 200, 64)           6223104   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 256)               197632    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 768)               197376    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 768)               3072      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 769       \n",
            "=================================================================\n",
            "Total params: 6,622,977\n",
            "Trainable params: 6,620,929\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiMeplYRYkCN",
        "colab_type": "code",
        "outputId": "3742c13c-e815-4020-cdb1-648b419f403b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model.fit(train_sequence, Y_train, nb_epoch=5, batch_size=512, validation_data=(cv_sequence, Y_cv))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 190911 samples, validate on 47728 samples\n",
            "Epoch 1/5\n",
            "190911/190911 [==============================] - 266s 1ms/step - loss: 0.2945 - acc: 0.8903 - val_loss: 0.2760 - val_acc: 0.8859\n",
            "Epoch 2/5\n",
            "190911/190911 [==============================] - 259s 1ms/step - loss: 0.1441 - acc: 0.9477 - val_loss: 0.1511 - val_acc: 0.9442\n",
            "Epoch 3/5\n",
            "190911/190911 [==============================] - 258s 1ms/step - loss: 0.1232 - acc: 0.9523 - val_loss: 0.1696 - val_acc: 0.9411\n",
            "Epoch 4/5\n",
            "190911/190911 [==============================] - 257s 1ms/step - loss: 0.1061 - acc: 0.9584 - val_loss: 0.1763 - val_acc: 0.9383\n",
            "Epoch 5/5\n",
            "190911/190911 [==============================] - 253s 1ms/step - loss: 0.0857 - acc: 0.9663 - val_loss: 0.1948 - val_acc: 0.9394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f28de5322e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKNc-qIudkz1",
        "colab_type": "code",
        "outputId": "2c83af66-177a-4150-acce-4724449bb946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Roc auc\n",
        "predicted_y = model.predict(test_sequence,batch_size=512)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(Y_test,predicted_y))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9038698075698687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdos0aE0NJdS",
        "colab_type": "text"
      },
      "source": [
        "## Second Bi-LSTM architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0feWATevhwF6",
        "colab_type": "code",
        "outputId": "973a4754-0ff6-4137-8d28-422df2502a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten, GlobalMaxPool1D\n",
        "from keras.layers import Dropout, BatchNormalization, Input\n",
        "from keras.layers import Dense, Bidirectional, concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "embedding_vector_length = 100\n",
        "input1 = Input(shape=(150,))\n",
        "x1 = Embedding(vocab_size,embedding_vector_length, input_length=150)(input1)\n",
        "x1 = Bidirectional(LSTM(200,return_sequences=True))(x1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "x1 = GlobalMaxPool1D()(x1)\n",
        "\n",
        "#input2 = Input(shape=(150,))\n",
        "x2 = Embedding(vocab_size,embedding_vector_length, input_length=150)(input1)\n",
        "x2 = Bidirectional(LSTM(200,return_sequences=True))(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = GlobalMaxPool1D()(x2)\n",
        "\n",
        "x = concatenate([x1, x2])\n",
        "x = Dense(75, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "model3 = Model(inputs=[input1,], outputs = output)\n",
        "#adam = Adam(lr=0.0001)\n",
        "model3.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 150, 100)     40000000    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 150, 100)     40000000    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 150, 400)     481600      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 150, 400)     481600      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 150, 400)     0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 150, 400)     0           bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 400)          0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_6 (GlobalM (None, 400)          0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 800)          0           global_max_pooling1d_5[0][0]     \n",
            "                                                                 global_max_pooling1d_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 75)           60075       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 75)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            76          dropout_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 81,023,351\n",
            "Trainable params: 81,023,351\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFz3kfS0hwEA",
        "colab_type": "code",
        "outputId": "30e05a7f-ced7-4d8a-c25e-38c6b7b35d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model3.fit(train_sequence, Y_train, epochs=4, batch_size=512, validation_data=[cv_sequence, Y_cv])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1282192 samples, validate on 142466 samples\n",
            "Epoch 1/4\n",
            "1282192/1282192 [==============================] - 4279s 3ms/step - loss: 0.1440 - acc: 0.9459 - val_loss: 0.1568 - val_acc: 0.9472\n",
            "Epoch 2/4\n",
            "1282192/1282192 [==============================] - 4267s 3ms/step - loss: 0.1159 - acc: 0.9536 - val_loss: 0.1421 - val_acc: 0.9489\n",
            "Epoch 3/4\n",
            "1282192/1282192 [==============================] - 4268s 3ms/step - loss: 0.0956 - acc: 0.9610 - val_loss: 0.1463 - val_acc: 0.9430\n",
            "Epoch 4/4\n",
            "1282192/1282192 [==============================] - 4270s 3ms/step - loss: 0.0711 - acc: 0.9714 - val_loss: 0.1569 - val_acc: 0.9380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dcd6d9b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6amyC__cyws",
        "colab_type": "code",
        "outputId": "eac82e49-bb03-453d-84bc-ffc8427aede3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Roc auc\n",
        "predicted_y = model3.predict(test_sequence,batch_size=512)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(Y_test,predicted_y))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9373771542809413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwbZScEQ2Pdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pre = model3.predict(test_sequence1,batch_size=512)\n",
        "submission = pd.DataFrame({'id': test_df['id'].values})\n",
        "submission['prediction'] = y_pre\n",
        "submission.to_csv(\"submission11.csv\",index=False) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHOY6RKX7k0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download( \"/content/submission11.csv\" )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkuzww6cN1-s",
        "colab_type": "text"
      },
      "source": [
        "## Third Bi-LSTM architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8oZknWteWTD",
        "colab_type": "code",
        "outputId": "c140ad09-5915-4258-f795-07fde471b1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten, GlobalMaxPool1D\n",
        "from keras.layers import Dropout, BatchNormalization, Input\n",
        "from keras.layers import Dense, Bidirectional, concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "embedding_vector_length = 100\n",
        "input1 = Input(shape=(150,))\n",
        "x1 = Embedding(vocab_size,embedding_vector_length, input_length=150)(input1)\n",
        "x1 = Bidirectional(LSTM(128,return_sequences=True))(x1)\n",
        "x1 = GlobalMaxPool1D()(x1)\n",
        "\n",
        "\n",
        "x2 = Embedding(vocab_size,embedding_vector_length, input_length=150)(input1)\n",
        "x2 = Bidirectional(LSTM(128,return_sequences=True))(x2)\n",
        "x2 = GlobalMaxPool1D()(x2)\n",
        "\n",
        "x = concatenate([x1, x2])\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "model4 = Model(inputs=[input1,], outputs = output)\n",
        "#adam = Adam(lr=0.0001)\n",
        "model4.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0830 05:13:28.912689 139808314402688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0830 05:13:28.966059 139808314402688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0830 05:13:28.973107 139808314402688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0830 05:13:30.026833 139808314402688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0830 05:13:30.035221 139808314402688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0830 05:13:30.064623 139808314402688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0830 05:13:30.086747 139808314402688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0830 05:13:30.092208 139808314402688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 150, 100)     40000000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 150, 100)     40000000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 150, 256)     234496      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 150, 256)     234496      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 256)          0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           32832       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 80,501,889\n",
            "Trainable params: 80,501,889\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmWZsrnveWXr",
        "colab_type": "code",
        "outputId": "e9634ddb-025d-4ca6-f97e-2409dae86cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model4.fit(train_sequence, Y_train, epochs=4, batch_size=512, validation_data=[cv_sequence, Y_cv])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1282192 samples, validate on 142466 samples\n",
            "Epoch 1/4\n",
            "1282192/1282192 [==============================] - 3407s 3ms/step - loss: 0.1435 - acc: 0.9465 - val_loss: 0.1267 - val_acc: 0.9496\n",
            "Epoch 2/4\n",
            "1282192/1282192 [==============================] - 3402s 3ms/step - loss: 0.1150 - acc: 0.9541 - val_loss: 0.1284 - val_acc: 0.9495\n",
            "Epoch 3/4\n",
            "1282192/1282192 [==============================] - 3397s 3ms/step - loss: 0.0936 - acc: 0.9622 - val_loss: 0.1432 - val_acc: 0.9477\n",
            "Epoch 4/4\n",
            "1282192/1282192 [==============================] - 3387s 3ms/step - loss: 0.0662 - acc: 0.9737 - val_loss: 0.1730 - val_acc: 0.9422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2704459c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7rLqgNKDf-5",
        "colab_type": "code",
        "outputId": "e72956f1-71b4-439a-d43c-bab9ff8dba47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train auc\n",
        "predicted_y = model4.predict(train_sequence,batch_size=512)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(Y_train,predicted_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9968805599682502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZe8EaOlE5MS",
        "colab_type": "code",
        "outputId": "393f33fc-b55b-4aac-f5d1-9626ebd8c5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Roc auc\n",
        "predicted_y = model4.predict(test_sequence,batch_size=512)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(Y_test,predicted_y))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.937064717518582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whFv3tqHTB0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pre = model4.predict(test_sequence1,batch_size=512)\n",
        "submission = pd.DataFrame({'id': test_df['id'].values})\n",
        "submission['prediction'] = y_pre\n",
        "submission.to_csv(\"submission12.csv\",index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFIT6L52X6Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download( \"/content/submission12.csv\" )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udNfnvCt77z9",
        "colab_type": "text"
      },
      "source": [
        "# Fourth Arcitecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kNfyrgT43rj",
        "colab_type": "code",
        "outputId": "25dc7a34-3909-4753-90ee-592e1558a6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install keras-self-attention"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/44/3e/eb1a7c7545eede073ceda2f5d78442b6cad33b5b750d7f0742866907c34b/keras-self-attention-0.42.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.16.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.42.0-cp36-none-any.whl size=17296 sha256=1b6748e2be03d9d3f6e020ff3336076401e4edf7ec86551552a8fce209a7b832\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/05/a0/99c0cf60d383f0494e10eca2b238ea98faca9a1fe03cac2894\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l43xwPS43kK",
        "colab_type": "code",
        "outputId": "f39eb9b1-50a7-479b-c444-d157f7d79b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import MaxPooling1D, Reshape\n",
        "from keras.layers import Flatten, GlobalMaxPool1D, GlobalAveragePooling1D\n",
        "from keras.layers import Dropout, BatchNormalization, Input, SpatialDropout1D\n",
        "from keras.layers import Dense, Bidirectional, concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "\n",
        "embedding_vector_length = 300\n",
        "input1 = Input(shape=(150,))\n",
        "e1 = Embedding(vocab_size,embedding_vector_length, input_length=150, weights=[embedding_matrix], trainable=False)(input1)\n",
        "x1 = Dropout(0.2)(e1)\n",
        "x1 = Bidirectional(LSTM(120, return_sequences=True))(e1)\n",
        "#lstm_att = SeqSelfAttention(attention_activation='sigmoid')(x1)\n",
        "\n",
        "gru1, fh_state, bh_state = Bidirectional(GRU(60, return_sequences= True, return_state=True))(x1)\n",
        "#x2 = SeqSelfAttention(attention_activation='sigmoid')(x2)\n",
        "\n",
        "h_state = concatenate([fh_state, bh_state])\n",
        "h_state = Reshape((-1,120))(h_state )\n",
        "\n",
        "h_avg = GlobalAveragePooling1D()(gru1)\n",
        "h_max = GlobalMaxPool1D()(gru1)\n",
        "\n",
        "h_avg = Reshape((-1,120))(h_avg )\n",
        "h_max = Reshape((-1,120))(h_max )\n",
        "\n",
        "\n",
        "x = concatenate([h_state, h_avg, h_max])\n",
        "x = Dense(20, activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Flatten()(x)\n",
        "#print(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "model5 = Model(inputs=[input1,], outputs = output)\n",
        "#adam = Adam(lr=0.001)\n",
        "model5.compile(loss= 'binary_crossentropy' , optimizer= 'adam', metrics=['accuracy',])\n",
        "model5.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"flatten_10/Reshape:0\", shape=(?, ?), dtype=float32)\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 150, 300)     71461200    input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_30 (Bidirectional (None, 150, 240)     404160      embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_31 (Bidirectional [(None, 150, 120), ( 108360      bidirectional_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 120)          0           bidirectional_31[0][1]           \n",
            "                                                                 bidirectional_31[0][2]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_7 (Glo (None, 120)          0           bidirectional_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_14 (Global (None, 120)          0           bidirectional_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 1, 120)       0           concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 1, 120)       0           global_average_pooling1d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 1, 120)       0           global_max_pooling1d_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 1, 360)       0           reshape_12[0][0]                 \n",
            "                                                                 reshape_13[0][0]                 \n",
            "                                                                 reshape_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1, 20)        7220        concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 1, 20)        0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 20)           0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            21          flatten_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 71,980,961\n",
            "Trainable params: 519,761\n",
            "Non-trainable params: 71,461,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWCvIKgc43hW",
        "colab_type": "code",
        "outputId": "cef172db-22c2-40f2-dd4a-ef0a51df406e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model5.fit(train_sequence, Y_train, epochs=6, batch_size=512, validation_data=[cv_sequence, Y_cv])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1282192 samples, validate on 142466 samples\n",
            "Epoch 1/6\n",
            "1282192/1282192 [==============================] - 2724s 2ms/step - loss: 0.1427 - acc: 0.9465 - val_loss: 0.1264 - val_acc: 0.9503\n",
            "Epoch 2/6\n",
            "1282192/1282192 [==============================] - 2730s 2ms/step - loss: 0.1237 - acc: 0.9516 - val_loss: 0.1253 - val_acc: 0.9507\n",
            "Epoch 3/6\n",
            "1282192/1282192 [==============================] - 2724s 2ms/step - loss: 0.1171 - acc: 0.9535 - val_loss: 0.1219 - val_acc: 0.9519\n",
            "Epoch 4/6\n",
            "1282192/1282192 [==============================] - 2713s 2ms/step - loss: 0.1104 - acc: 0.9556 - val_loss: 0.1253 - val_acc: 0.9505\n",
            "Epoch 5/6\n",
            "1282192/1282192 [==============================] - 2713s 2ms/step - loss: 0.1026 - acc: 0.9581 - val_loss: 0.1263 - val_acc: 0.9506\n",
            "Epoch 6/6\n",
            "1282192/1282192 [==============================] - 2724s 2ms/step - loss: 0.0933 - acc: 0.9612 - val_loss: 0.1340 - val_acc: 0.9492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0cc1757d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lfqtrN-Ggkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating loss metric\n",
        "j_eval = JigsawEvaluator(y_binary, y_identity_binary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeO14m8dGz4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_y = model5.predict(test_sequence,batch_size=512)\n",
        "final_auc = j_eval.get_final_metric(predicted_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7k952YEFukt",
        "colab_type": "code",
        "outputId": "03b89787-3d2e-4e2c-c535-954d80687861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This is the auc metric that was given by kaggle.\n",
        "print(\"Auc of the model is {}\".format(final_auc))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc of the model is 0.9118993070137469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB6Y70mXOUwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_y1 = (predicted_y >= 0.5).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B6xpRPmOIjq",
        "colab_type": "code",
        "outputId": "31fe59ae-6392-4247-f019-e4abc49295b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This is the simple auc on test data\n",
        "print(roc_auc_score(Y_test, predicted_y))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9550143824173905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRxZjb0lKNb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y = model5.predict(test_sequence1,batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhQ4i1ur7QnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving model to google drive\n",
        "from keras.models import load_model\n",
        "model5.save(\"/content/drive/My Drive/Project/my_model5.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zSl7Cnz43U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_pre = model5.predict(test_sequence1,batch_size=32)\n",
        "submission = pd.DataFrame({'id': test_df['id'].values})\n",
        "submission['prediction'] = predict_y\n",
        "submission.to_csv(\"submission18.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4K80WM42s9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download( \"/content/submission18.csv\" )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eanGYB2fDNVk",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdSq7i99e70t",
        "colab_type": "code",
        "outputId": "073fbfe2-0005-46ec-8c7d-1a3448de99b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "x = PrettyTable(['model','vectorizer','test auc'])\n",
        "x.add_row(['Logistic Regression','tfidf unigram','0.9465'])\n",
        "x.add_row(['Naive Bayes','tfidf unigram','0.8755'])\n",
        "x.add_row(['1 layered Bi-LSTM + self attention layer','glove 100dim ','0.8823'])\n",
        "x.add_row(['1 layered Bi-LSTM','glove 100dim','0.9038'])\n",
        "x.add_row(['2 layered Bi-LSTM(200 units)','glove 100dim ','0.9373'])\n",
        "x.add_row(['2 layered Bi-LSTM(128 units)','glove 100dim ','0.9370'])\n",
        "x.add_row(['1 layered Bi-LSTM(120 units) + 1 layered Bi-gru(60) units','glove 300dim ','0.9550'])\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------+---------------+----------+\n",
            "|                           model                           |   vectorizer  | test auc |\n",
            "+-----------------------------------------------------------+---------------+----------+\n",
            "|                    Logistic Regression                    | tfidf unigram |  0.9465  |\n",
            "|                        Naive Bayes                        | tfidf unigram |  0.8755  |\n",
            "|          1 layered Bi-LSTM + self attention layer         | glove 100dim  |  0.8823  |\n",
            "|                     1 layered Bi-LSTM                     |  glove 100dim |  0.9038  |\n",
            "|                2 layered Bi-LSTM(200 units)               | glove 100dim  |  0.9373  |\n",
            "|                2 layered Bi-LSTM(128 units)               | glove 100dim  |  0.9370  |\n",
            "| 1 layered Bi-LSTM(120 units) + 1 layered Bi-gru(60) units | glove 300dim  |  0.9550  |\n",
            "+-----------------------------------------------------------+---------------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX3UKgS38vov",
        "colab_type": "text"
      },
      "source": [
        "## The best model that we had was the fourth and the last model that gave us an auc of 0.9176 on the kaggle private leader board."
      ]
    }
  ]
}